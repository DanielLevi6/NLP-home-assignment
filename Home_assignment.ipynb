{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hb1Kyd94F9Xt",
    "outputId": "7b1c0c12-9c4e-4075-a502-7bb01059d1e9"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import nltk\n",
    "import re\n",
    "import wget\n",
    "from sys import getsizeof\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "nltk.download('punkt', quiet=True) # this module is used to tokenize the text\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hHl3jP8BNA_r"
   },
   "outputs": [],
   "source": [
    "# Some utilities to manipulate the corpus\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"Strips #comments and empty lines from a string\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        line = re.sub('#.*$', '', line)\n",
    "        if line != '':\n",
    "            result.append(line)\n",
    "    return result\n",
    "\n",
    "def nltk_normpunc_tokenize(str):\n",
    "    return nltk.tokenize.word_tokenize(str.lower())\n",
    "\n",
    "def split(list, portions, offset):\n",
    "    return ([list[i] for i in range(0, len(list)) if i%portions != offset],\n",
    "          [list[i] for i in range(0, len(list)) if i%portions == offset])\n",
    "\n",
    "def SMSSpamCollection_tokenize(lines):\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        # tokenize\n",
    "        tokens = nltk_normpunc_tokenize(line)\n",
    "        if tokens[0] == \"ham\":\n",
    "            tokens[0] = \"HAM:\"\n",
    "        elif tokens[0] == \"spam\":\n",
    "            tokens[0] = \"SPAM:\"\n",
    "        # add a start of message token\n",
    "        result += [\"<s>\"] + tokens\n",
    "\n",
    "    return result\n",
    "\n",
    "def postprocess(tokens):\n",
    "    return ' '.join(tokens)\\\n",
    "                .replace(\"<s> \", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMSplbxbD2Sm"
   },
   "source": [
    "Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data//SMSSpamCollection.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_filename = (\"https://github.com/DanielLevi6/NLP-home-assignment/tree/main/data/\"\n",
    "                  \"SMSSpamCollection.txt\")\n",
    "os.makedirs('data', exist_ok=True)\n",
    "wget.download(corpus_filename, out=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbxCTsLiD7L4"
   },
   "source": [
    "Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iiLGSGjHE8Le"
   },
   "outputs": [],
   "source": [
    "with open(\"data/SMSSpamCollection.txt\", 'r') as fin:\n",
    "    lines = preprocess(fin.read())[:40]\n",
    "    train_lines, test_lines = split(lines, 12, 0)\n",
    "    train_tokens = SMSSpamCollection_tokenize(train_lines)\n",
    "    test_tokens = SMSSpamCollection_tokenize(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<', 'html', 'lang=', \"''\", 'en', \"''\", 'data-color-mode=', \"''\", 'auto', \"''\", 'data-light-theme=', \"''\", 'light', \"''\", 'data-dark-theme=', \"''\", 'dark', \"''\", 'data-a11y-animated-images=', \"''\", 'system', \"''\", '>', '<s>', '<', 'head', '>', '<s>', '<', 'meta', 'charset=', \"''\", 'utf-8', \"''\", '>', '<s>', '<', 'link', 'rel=', \"''\", 'dns-prefetch', \"''\", 'href=', \"''\", 'https', ':', '//github.githubassets.com', \"''\", '>']\n",
      "\n",
      "< html lang= '' en '' data-color-mode= '' auto '' data-light-theme= '' light '' data-dark-theme= '' dark '' data-a11y-animated-images= '' system '' > \n",
      "< head > \n",
      "< meta charset= '' utf-8 '' > \n",
      "< link rel= '' dns-prefetch '' href= '' https : //github.githubassets.com '' >\n",
      "['<s>', '<', '!', 'doctype', 'html', '>', '<s>', '<', 'link', 'crossorigin=', \"''\", 'anonymous', \"''\", 'media=', \"''\", 'all', \"''\", 'rel=', \"''\", 'stylesheet', \"''\", 'href=', \"''\", 'https', ':', '//github.githubassets.com/assets/primer-7e8db5e0affc.css', \"''\", '/', '>', '<s>', '<', 'script', 'crossorigin=', \"''\", 'anonymous', \"''\", 'defer=', \"''\", 'defer', \"''\", 'type=', \"''\", 'application/javascript', \"''\", 'src=', \"''\", 'https', ':', '//github.githubassets.com/assets/vendors-node_modules_fzy_js_index_js-node_modules_github_markdown-toolbar-element_dist_index_js-e3de700a4c9d.js', \"''\"]\n",
      "\n",
      "< ! doctype html > \n",
      "< link crossorigin= '' anonymous '' media= '' all '' rel= '' stylesheet '' href= '' https : //github.githubassets.com/assets/primer-7e8db5e0affc.css '' / > \n",
      "< script crossorigin= '' anonymous '' defer= '' defer '' type= '' application/javascript '' src= '' https : //github.githubassets.com/assets/vendors-node_modules_fzy_js_index_js-node_modules_github_markdown-toolbar-element_dist_index_js-e3de700a4c9d.js ''\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[:50])\n",
    "print(postprocess(train_tokens[:50]))\n",
    "print(test_tokens[:50])\n",
    "print(postprocess(test_tokens[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EejBl8nfCibe"
   },
   "outputs": [],
   "source": [
    "# Extract vocabulary from dataset\n",
    "vocabulary = list(set(train_tokens)) + list(set(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jY8Ujeot0hea"
   },
   "outputs": [],
   "source": [
    "# Creating the n-grams\n",
    "def all_ngrams(vocabulary, n):\n",
    "    return list(itertools.product(vocabulary, repeat=n))\n",
    "\n",
    "def ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(0, len(tokens)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCH-gJRkD_za",
    "outputId": "070acedb-0de4-4ab5-fda1-59b176e190a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<', 'html', 'lang=', \"''\", 'en']\n",
      "[('<s>', '<', 'html'), ('<', 'html', 'lang='), ('html', 'lang=', \"''\"), ('lang=', \"''\", 'en')]\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[:6])\n",
    "print(ngrams(train_tokens[:6], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wilWVIGGERv7"
   },
   "outputs": [],
   "source": [
    "# Counting the ngrams\n",
    "def ngram_counts(vocabulary, tokens, n):\n",
    "    context_dict = defaultdict(lambda: defaultdict(int))\n",
    "    for context in all_ngrams(vocabulary, n-1):\n",
    "        for target in vocabulary:\n",
    "            context_dict[context][target] = 0\n",
    "\n",
    "    for ngram, count in Counter(ngrams(tokens, n)).items():\n",
    "        context_dict[ngram[:-1]][ngram[-1]] = count\n",
    "\n",
    "    return context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hZu_gMOQFPbr"
   },
   "outputs": [],
   "source": [
    "unigram_counts = ngram_counts(vocabulary, train_tokens, 1)\n",
    "bigram_counts = ngram_counts(vocabulary, train_tokens, 2)\n",
    "trigram_counts = ngram_counts(vocabulary, train_tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_count = len(train_tokens)\n",
    "unigram_count = sum(len(unigram_counts[cntxt]) for cntxt in unigram_counts)\n",
    "bigram_count = sum(len(bigram_counts[cntxt]) for cntxt in bigram_counts)\n",
    "trigram_count = sum(len(trigram_counts[cntxt]) for cntxt in trigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:   6569\n",
      "Unigrams:    392\n",
      "Bigrams: 153664\n",
      "Trigrams: 60236288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report on the totals\n",
    "print(f\"Tokens: {tokens_count:6}\\n\"\n",
    "     f\"Unigrams: {unigram_count:6}\\n\"\n",
    "     f\"Bigrams: {bigram_count:6}\\n\"\n",
    "     f\"Trigrams: {trigram_count:6}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_model(ngram_counts):\n",
    "    probs = defaultdict(lambda: defaultdict(int))\n",
    "    for cntxt, distrib in ngram_counts.items():\n",
    "        total_count = sum(distrib.values())\n",
    "        for token in distrib:\n",
    "            probs[cntxt][token] = distrib[token] / total_count if total_count > 0 else 0.0\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = ngram_model(unigram_counts)\n",
    "bigram_model = ngram_model(bigram_counts)\n",
    "trigram_model = ngram_model(trigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  54712\n",
      "Unigrams:    240\n",
      "Bigrams:  18528\n",
      "Trigrams: 5242976\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens: {getsizeof(train_tokens):6}\\n\"\n",
    "      f\"Unigrams: {getsizeof(unigram_model):6}\\n\"\n",
    "      f\"Bigrams: {getsizeof(bigram_model):6}\\n\"\n",
    "      f\"Trigrams: {getsizeof(trigram_model):6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity - unigram: inf\n",
      "Test perplexity - bigram: inf\n",
      "Test perplexity - trigram: inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perplexity calculation\n",
    "import math\n",
    "\n",
    "def neglogprob(tokens, model, n):\n",
    "    score = 0.0\n",
    "    context = tokens[0:n-1]\n",
    "    for token in tokens[n-1:]:\n",
    "        prob = model[tuple(context)][token]\n",
    "        score += -math.log2(prob) if prob > 0 else math.inf\n",
    "        context = (context +[token])[1:]\n",
    "    \n",
    "    return score\n",
    "\n",
    "def perplexity(tokens, model, n):\n",
    "    return 2**(neglogprob(tokens, model, n) / (len(tokens) -n +1))\n",
    "\n",
    "print(f\"Test perplexity - unigram: {perplexity(test_tokens, unigram_model, 1):.3f}\\n\"\n",
    "      f\"Test perplexity - bigram: {perplexity(test_tokens, bigram_model, 2):.3f}\\n\"\n",
    "      f\"Test perplexity - trigram: {perplexity(test_tokens, trigram_model, 3):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta smoothing\n",
    "\n",
    "def ngram_model_smoothed(ngram_counts, delta=2):\n",
    "    vocab_size = len(list(ngram_counts.items())[0][1])\n",
    "    probs = defaultdict(lambda: defaultdict(int))\n",
    "    for cntxt, distrib in ngram_counts.items():\n",
    "        total_count = sum(distrib.values())\n",
    "        for token in distrib:\n",
    "            probs[cntxt][token] = (distrib[token] + delta) / (total_count + vocab_size * delta)\n",
    "            if probs[cntxt][token] == 0:\n",
    "                print(\"{context} {token} prob is zero\")\n",
    "                \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test smoothed perplexity - unigram: 123.649\n",
      "Test smoothed perplexity - bigram: 50.845\n",
      "Test smoothed perplexity - trigram: 58.432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_model_smoothed = ngram_model_smoothed(unigram_counts)\n",
    "bigram_model_smoothed = ngram_model_smoothed(bigram_counts)\n",
    "trigram_model_smoothed = ngram_model_smoothed(trigram_counts)\n",
    "print(f\"Test smoothed perplexity - unigram: {perplexity(test_tokens, unigram_model_smoothed, 1):.3f}\\n\"\n",
    "      f\"Test smoothed perplexity - bigram: {perplexity(test_tokens, bigram_model_smoothed, 2):.3f}\\n\"\n",
    "      f\"Test smoothed perplexity - trigram: {perplexity(test_tokens, trigram_model_smoothed, 3):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_model_smoothed_kneser_ney(ngram_model, test_data, n):\n",
    "    # Compute total number of words in test data\n",
    "    total_words = len(test_data)\n",
    "\n",
    "    # Compute the count of n-grams in the training data\n",
    "    ngram_counts = defaultdict(int)\n",
    "    for ngram in ngram_model:\n",
    "        ngram_counts[ngram] += 1\n",
    "\n",
    "    # Compute the count of unique n-1 grams in the training data\n",
    "    n_1gram_counts = defaultdict(int)\n",
    "    for ngram in ngram_model:\n",
    "        n_1gram = tuple(ngram[:-1])\n",
    "        n_1gram_counts[n_1gram] += 1\n",
    "\n",
    "    # Compute the total number of unique n-1 grams in the training data\n",
    "    total_n_1grams = len(n_1gram_counts)\n",
    "\n",
    "    # Compute the total number of unique words in the training data\n",
    "    total_vocabulary = len(set([word for ngram in ngram_model for word in ngram]))\n",
    "\n",
    "    # Compute the perplexity of the test data\n",
    "    log_prob = 0.0\n",
    "    for i in range(n-1, len(test_data)):\n",
    "        ngram = tuple(test_data[i-n+1:i+1])\n",
    "        n_1gram = ngram[:-1]\n",
    "\n",
    "        count_ngram = ngram_counts[ngram]\n",
    "        count_n_1gram = n_1gram_counts[n_1gram]\n",
    "\n",
    "        prob = max(count_ngram - 0.75, 0) / count_n_1gram\n",
    "        prob += (0.75 / count_n_1gram) * (total_n_1grams / total_vocabulary)\n",
    "\n",
    "        log_prob += math.log2(prob)\n",
    "\n",
    "    perplexity = 2 ** (-log_prob / total_words)\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kneser_ney_perplexity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unigram_model_kneser_ney_smoothed \u001b[38;5;241m=\u001b[39m \u001b[43mkneser_ney_perplexity\u001b[49m(unigram_counts)\n\u001b[1;32m      2\u001b[0m bigram_model_kneser_ney_smoothed \u001b[38;5;241m=\u001b[39m kneser_ney_perplexity(bigram_counts)\n\u001b[1;32m      3\u001b[0m trigram_model_kneser_ney_smoothed \u001b[38;5;241m=\u001b[39m kneser_ney_perplexity(trigram_counts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kneser_ney_perplexity' is not defined"
     ]
    }
   ],
   "source": [
    "unigram_model_kneser_ney_smoothed = kneser_ney_perplexity(unigram_counts)\n",
    "bigram_model_kneser_ney_smoothed = kneser_ney_perplexity(bigram_counts)\n",
    "trigram_model_kneser_ney_smoothed = kneser_ney_perplexity(trigram_counts)\n",
    "print(f\"Test smoothed perplexity - unigram: {perplexity(test_tokens, unigram_model_smoothed, 1):.3f}\\n\"\n",
    "      f\"Test smoothed perplexity - bigram: {perplexity(test_tokens, bigram_model_smoothed, 2):.3f}\\n\"\n",
    "      f\"Test smoothed perplexity - trigram: {perplexity(test_tokens, trigram_model_smoothed, 3):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
